2025-03-10 19:14:03,140 INFO    Thread-4  :65105 [wandb_setup.py:_flush():67] Current SDK version is 0.19.8
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_setup.py:_flush():67] Configure stats pid to 65105
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_setup.py:_flush():67] Loading settings from /Users/mariegoffin/.config/wandb/settings
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_setup.py:_flush():67] Loading settings from /Users/mariegoffin/Documents/Master_3/IML/projects/L2D/wandb_test/wandb/settings
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_init.py:setup_run_log_directory():647] Logging user logs to /Users/mariegoffin/Documents/Master_3/IML/projects/L2D/wandb_test/wandb/run-20250310_191403-4drt25x8/logs/debug.log
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to /Users/mariegoffin/Documents/Master_3/IML/projects/L2D/wandb_test/wandb/run-20250310_191403-4drt25x8/logs/debug-internal.log
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_init.py:init():761] calling init triggers
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_init.py:init():766] wandb.init called with sweep_config: {'entloss_coef': 0.05, 'eps_clip': 0.2, 'feature_set': 'LBs,finished_mark,weighted_priorities,normalized_weights,remaining_weighted_work', 'hidden_dim': 64, 'hidden_dim_actor': 32, 'hidden_dim_critic': 32, 'k_epochs': 1, 'log_every': 50, 'lr': 1e-05, 'max_updates': 1000, 'num_envs': 16, 'num_layers': 3, 'num_mlp_layers_actor': 2, 'num_mlp_layers_critic': 2, 'num_mlp_layers_feature_extract': 2}
config: {'_name': 'wandb.config', '__doc__': 'Config object.\n\n    Config objects are intended to hold all of the hyperparameters associated with\n    a wandb run and are saved with the run object when `wandb.init` is called.\n\n    We recommend setting `wandb.config` once at the top of your training experiment or\n    setting the config as a parameter to init, ie. `wandb.init(config=my_config_dict)`\n\n    You can create a file called `config-defaults.yaml`, and it will automatically be\n    loaded into `wandb.config`. See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    You can also load a config YAML file with your custom name and pass the filename\n    into `wandb.init(config="special_config.yaml")`.\n    See https://docs.wandb.com/guides/track/config#file-based-configs.\n\n    Examples:\n        Basic usage\n        ```\n        wandb.config.epochs = 4\n        wandb.init()\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Using wandb.init to set config\n        ```\n        wandb.init(config={"epochs": 4, "batch_size": 32})\n        for x in range(wandb.config.epochs):\n            # train\n        ```\n\n        Nested configs\n        ```\n        wandb.config[\'train\'][\'epochs\'] = 4\n        wandb.init()\n        for x in range(wandb.config[\'train\'][\'epochs\']):\n            # train\n        ```\n\n        Using absl flags\n        ```\n        flags.DEFINE_string("model", None, "model to run")  # name, default, help\n        wandb.config.update(flags.FLAGS)  # adds all absl flags to config\n        ```\n\n        Argparse flags\n        ```python\n        wandb.init()\n        wandb.config.epochs = 4\n\n        parser = argparse.ArgumentParser()\n        parser.add_argument(\n            "-b",\n            "--batch-size",\n            type=int,\n            default=8,\n            metavar="N",\n            help="input batch size for training (default: 8)",\n        )\n        args = parser.parse_args()\n        wandb.config.update(args)\n        ```\n\n        Using TensorFlow flags (deprecated in tensorflow v2)\n        ```python\n        flags = tf.app.flags\n        flags.DEFINE_string("data_dir", "/tmp/data")\n        flags.DEFINE_integer("batch_size", 128, "Batch size.")\n        wandb.config.update(flags.FLAGS)  # adds all of the tensorflow flags to config\n        ```\n    ', '_wandb': {}}
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_init.py:init():784] starting backend
2025-03-10 19:14:03,141 INFO    Thread-4  :65105 [wandb_init.py:init():788] sending inform_init request
2025-03-10 19:14:03,209 INFO    Thread-4  :65105 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2025-03-10 19:14:03,209 INFO    Thread-4  :65105 [wandb_init.py:init():798] backend started and connected
2025-03-10 19:14:03,210 INFO    Thread-4  :65105 [wandb_run.py:_config_callback():1261] config_cb None None {'entloss_coef': 0.05, 'eps_clip': 0.2, 'feature_set': 'LBs,finished_mark,weighted_priorities,normalized_weights,remaining_weighted_work', 'hidden_dim': 64, 'hidden_dim_actor': 32, 'hidden_dim_critic': 32, 'k_epochs': 1, 'log_every': 50, 'lr': 1e-05, 'max_updates': 1000, 'num_envs': 16, 'num_layers': 3, 'num_mlp_layers_actor': 2, 'num_mlp_layers_critic': 2, 'num_mlp_layers_feature_extract': 2}
2025-03-10 19:14:03,212 INFO    Thread-4  :65105 [wandb_init.py:init():891] updated telemetry
2025-03-10 19:14:03,236 INFO    Thread-4  :65105 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-03-10 19:14:03,871 INFO    Thread-4  :65105 [wandb_init.py:init():990] starting run threads in backend
2025-03-10 19:14:03,955 INFO    Thread-4  :65105 [wandb_run.py:_console_start():2375] atexit reg
2025-03-10 19:14:03,956 INFO    Thread-4  :65105 [wandb_run.py:_redirect():2227] redirect: wrap_raw
2025-03-10 19:14:03,956 INFO    Thread-4  :65105 [wandb_run.py:_redirect():2292] Wrapping output streams.
2025-03-10 19:14:03,956 INFO    Thread-4  :65105 [wandb_run.py:_redirect():2315] Redirects installed.
2025-03-10 19:14:03,958 INFO    Thread-4  :65105 [wandb_init.py:init():1032] run started, returning control to user process
2025-03-10 19:14:03,958 INFO    Thread-4  :65105 [wandb_run.py:_finish():2112] finishing run fredrichthomas00-university-of-li-ge/jssp-weighted-sum/4drt25x8
2025-03-10 19:14:03,958 INFO    Thread-4  :65105 [wandb_run.py:_atexit_cleanup():2340] got exitcode: 1
2025-03-10 19:14:03,958 INFO    Thread-4  :65105 [wandb_run.py:_restore():2322] restore
2025-03-10 19:14:03,958 INFO    Thread-4  :65105 [wandb_run.py:_restore():2328] restore done
2025-03-10 19:14:05,329 INFO    Thread-4  :65105 [wandb_run.py:_footer_history_summary_info():3956] rendering history
2025-03-10 19:14:05,329 INFO    Thread-4  :65105 [wandb_run.py:_footer_history_summary_info():3988] rendering summary
2025-03-10 19:14:05,329 INFO    Thread-4  :65105 [wandb_run.py:_footer_sync_info():3917] logging synced files
